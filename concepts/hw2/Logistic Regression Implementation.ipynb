{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Likelihood-definition:-the-theoretical-probability-of-having-gotten-the-observed-outcomes.\" data-toc-modified-id=\"Likelihood-definition:-the-theoretical-probability-of-having-gotten-the-observed-outcomes.-0.0.1\"><span class=\"toc-item-num\">0.0.1&nbsp;&nbsp;</span>Likelihood definition: the theoretical probability of having gotten the observed outcomes.</a></span></li><li><span><a href=\"#Objective:-$\\hat{\\theta}_{MLE}-=-\\underset{\\theta}{\\mathrm{argmin}}&#10;\\-L(\\theta;-x_1,x_2,....,x_n)$\" data-toc-modified-id=\"Objective:-$\\hat{\\theta}_{MLE}-=-\\underset{\\theta}{\\mathrm{argmin}}\n",
    "\\-L(\\theta;-x_1,x_2,....,x_n)$-0.0.2\"><span class=\"toc-item-num\">0.0.2&nbsp;&nbsp;</span>Objective: $\\hat{\\theta}_{MLE} = \\underset{\\theta}{\\mathrm{argmin}}\n",
    "\\ L(\\theta; x_1,x_2,....,x_n)$</a></span></li><li><span><a href=\"#(conditional)-Likelihood-function-to-maximize\" data-toc-modified-id=\"(conditional)-Likelihood-function-to-maximize-0.0.3\"><span class=\"toc-item-num\">0.0.3&nbsp;&nbsp;</span>(conditional) Likelihood function to maximize</a></span></li><li><span><a href=\"#Link-function:\" data-toc-modified-id=\"Link-function:-0.0.4\"><span class=\"toc-item-num\">0.0.4&nbsp;&nbsp;</span>Link function:</a></span></li><li><span><a href=\"#Log-(conditional)-likelihood-function-to-maximize\" data-toc-modified-id=\"Log-(conditional)-likelihood-function-to-maximize-0.0.5\"><span class=\"toc-item-num\">0.0.5&nbsp;&nbsp;</span>Log (conditional) likelihood function to maximize</a></span></li><li><span><a href=\"#Update-rule-for-maximization-of-likelihood:\" data-toc-modified-id=\"Update-rule-for-maximization-of-likelihood:-0.0.6\"><span class=\"toc-item-num\">0.0.6&nbsp;&nbsp;</span>Update rule for maximization of likelihood:</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCncRkRT0/wHojPcdrY5zGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3425e46518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('coronary_heart_disease.csv')\n",
    "\n",
    "def s(x):\n",
    "    return 1 / (1 + np.exp(- x))\n",
    "\n",
    "domain = [-6,-5,-4,-3,-2,-1,0,1,2,3,4,5,6]\n",
    "plt.plot(domain, [s(a) for a in domain])\n",
    "plt.title('Sigmoid function on domain [-6,6]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>CHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  CHD\n",
       "0   20    0\n",
       "1   23    0\n",
       "2   24    0\n",
       "3   25    1\n",
       "4   25    0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('coronary_heart_disease.csv')\n",
    "X = data['Age']\n",
    "y = data['CHD']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood definition: the theoretical probability of having gotten the observed outcomes.\n",
    "\n",
    "So in maximizing likelihood over all choices of theta, you can imagine that we are trying to recreate in our model the probability distribution (which would be Bernoulli in this case) from which the data is realized (because I believe that this would actually maximize the probability of having gotten the data we observed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective: $\\hat{\\theta}_{MLE} = \\underset{\\theta}{\\mathrm{argmin}}\n",
    "\\ L(\\theta; x_1,x_2,....,x_n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (conditional) Likelihood function to maximize\n",
    "$$ L(\\theta; x_1, x_2,...,x_n) = \\prod_{i=1}^{N} p_{i}^{y_i}(1 - p_i)^{1 - y_i},$$\n",
    "<br>\n",
    "where $p_i = p(Y = 1 \\mid x_i; \\theta) = \\sigma(\\sum_{j=1}^{M} \\theta_jx_{ij}) = \\dfrac{1}{1 + \\mathrm{e}^{-(\\sum_{j=1}^{M} \\theta_jx_{ij})}}$\n",
    "###### Note that the $\\theta_0$ value is assumed to be included in the vector and $x_0 = 1$\n",
    "###### Note also that the \"where\" line is an assumption; we are assuming that the probability that Y = 1 is a nonlinear function (sigmoid function) of a linear function of x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link function: \n",
    "This function, $g$, takes the mean response and returns back the linear combination of predictors and theta. $g$ is the inverse of the sigmoid function. Therefore, $g^{-1}(z)$ will be your prediction (i.e. $p(Y = 1 \\mid X; \\theta)$), where $z$ is the linear combination of theta and your predictors. This is how logistic regression fits into generalized linear models. Note that for generalized linear models use only exponential family distributions to model the response variable. \n",
    "\n",
    "The below equation gives the log odds for a single training example (x value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\log\\dfrac{p}{1-p} = \\sum_{j=1}^{M} \\theta_jx_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log (conditional) likelihood function to maximize\n",
    "\n",
    "This can be done because log is a monotonic function (always increasing => x1 > x2 => log(x1) > log(x2)). This means that the same theta that maximizes the log likelihood also maximizes the likelihood. This also makes the likelihood much easier to differentiate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "LCL = \\sum_{i=1}^{N}\\log L(\\theta; y_i \\mid x_i) \n",
    "    = \\sum_{i:y_i=1} \\log p_i + \\sum_{i:y_i=0} \\log (1 - p_i) \n",
    "    = \\sum_{i=1}^{N} y_i\\log p_i + (1-y_i)\\log(1 - p_i) \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(theta, X_train, y_train):\n",
    "    s = 0.0\n",
    "    for i in range(len(X_train)):\n",
    "        p = sigmoid_hypothesis(theta, X_train[i, :])\n",
    "        s += y_train[i]*np.log(p) + (1-y_train[i])*np.log(1-p)\n",
    "    return s\n",
    "\n",
    "def sigmoid_hypothesis(theta, x):\n",
    "    return 1 / (1 + np.exp(-np.dot(theta, x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update rule for maximization of likelihood:\n",
    "$$ \\beta_j = \\beta_j + \\alpha \\sum_{i=1}^{N} (y_i - p_i)x_{ij}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.83754541e+00,   1.83776165e-03])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ga_element_wise(theta, X_train, y_train, alpha):\n",
    "    diff_y_p = np.zeros([len(y_train)])\n",
    "    for m in range(len(y_train)):\n",
    "            diff_y_p[m] = \\\n",
    "            sigmoid_hypothesis(theta, \n",
    "                               X_train[m, :]) - y_train[m]\n",
    "    for j in range(len(theta)):\n",
    "        # This is the sum next to alpha \n",
    "        s = 0.0\n",
    "        for m in range(len(y_train)):\n",
    "            s += diff_y_p[m] * X_train[m, j]\n",
    "        theta[j] = theta[j] - alpha * s\n",
    "        \n",
    "def pretrain(X_train, y_train, add_intercept=True):\n",
    "    if y_train.ndim != 1: \n",
    "        raise Exception('y_train should be 1D')\n",
    "    y_train = np.array(y_train)\n",
    "    if X_train.ndim == 1: \n",
    "        X_train = np.array([np.array([x]) for x in X_train])\n",
    "    # Add intercept for x_0 = 1 \n",
    "    if add_intercept:\n",
    "        # insert goes arr, index, value, dimension to insert\n",
    "        # it will insert for each array in the given dimension\n",
    "        # i.e. it is broadcasted \n",
    "        X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "        \n",
    "    return [X_train, y_train]\n",
    "        \n",
    "def train_element_wise(X_train, y_train, max_iter, alpha, \n",
    "                      add_intercept=True):\n",
    "    X_train, y_train = pretrain(X_train, y_train, add_intercept)\n",
    "        \n",
    "    # length of theta should be === # features \n",
    "    theta = np.zeros(X_train.shape[1])\n",
    "    for i in range(max_iter):\n",
    "        ga_element_wise(theta, X_train, y_train, alpha)       \n",
    "    return theta\n",
    "\n",
    "train_element_wise(X_train, y_train, 1000, .001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THETA [-0.0135  0.039 ] -69.3555197733\n",
      "THETA [-1.355847    4.35956947] nan\n",
      "THETA [-2.80364278  4.45343819] nan\n",
      "THETA [-4.24536113  4.37248035] nan\n",
      "THETA [-5.67771637  4.33118021] nan\n",
      "THETA [-7.0992793   4.53921203] nan\n",
      "THETA [-8.52170231  4.49719591] nan\n",
      "THETA [-9.94087622  4.48274925] nan\n",
      "THETA [-11.35569232   4.62014881] nan\n",
      "THETA [-12.77262973   4.54293895] nan\n",
      "THETA [-14.1908923    4.31546036] nan\n",
      "THETA [-15.60532133   4.26820713] nan\n",
      "THETA [-17.01258263   4.62415278] nan\n",
      "THETA [-18.42373213   4.70432999] nan\n",
      "THETA [-19.83899966   4.49199258] nan\n",
      "THETA [-21.24919103   4.57546813] nan\n",
      "THETA [-22.65679097   4.80936271] nan\n",
      "THETA [-24.06843318   4.76104334] nan\n",
      "THETA [-25.47957027   4.73608036] nan\n",
      "THETA [-26.89285354   4.5463816 ] nan\n",
      "THETA [-28.2998199    4.73838997] nan\n",
      "THETA [-29.71187493   4.59160398] nan\n",
      "THETA [-31.11653709   4.90721028] nan\n",
      "THETA [-32.52794013   4.77508185] nan\n",
      "THETA [-33.93617349   4.85565739] nan\n",
      "THETA [-35.34303073   5.0015568 ] nan\n",
      "THETA [-36.75430566   4.84148626] nan\n",
      "THETA [-38.16218185   4.89883706] nan\n",
      "THETA [-39.56839982   5.0541649 ] nan\n",
      "THETA [-40.97805826   4.97301288] nan\n",
      "THETA [-42.38728522   4.91293886] nan\n",
      "THETA [-43.79326479   5.06899777] nan\n",
      "THETA [-45.20052367   5.11755102] nan\n",
      "THETA [-46.60807843   5.14446641] nan\n",
      "THETA [-48.01522908   5.18523354] nan\n",
      "THETA [-49.42416672   5.10779808] nan\n",
      "THETA [-50.83020417   5.21058102] nan\n",
      "THETA [-52.23770541   5.21463806] nan\n",
      "THETA [-53.64491336   5.23616122] nan\n",
      "THETA [-55.05174037   5.28103491] nan\n",
      "THETA [-56.45868485   5.31424567] nan\n",
      "THETA [-57.86693741   5.2616939 ] nan\n",
      "THETA [-59.27507768   5.21321049] nan\n",
      "THETA [-60.68006755   5.37559944] nan\n",
      "THETA [-62.08799574   5.33454468] nan\n",
      "THETA [-63.4959734    5.28469916] nan\n",
      "THETA [-64.90154993   5.38489051] nan\n",
      "THETA [-66.30759992   5.4439041 ] nan\n",
      "THETA [-67.71427924   5.45885985] nan\n",
      "THETA [-69.120843     5.47959358] nan\n",
      "THETA [-70.52804181   5.45457206] nan\n",
      "THETA [-71.93364028   5.53740046] nan\n",
      "THETA [-73.34172189   5.44912129] nan\n",
      "THETA [-74.74696783   5.55275524] nan\n",
      "THETA [-76.15331593   5.57983138] nan\n",
      "THETA [-77.55981609   5.59711994] nan\n",
      "THETA [-78.96649484   5.5981754 ] nan\n",
      "THETA [-80.372804   5.624004] nan\n",
      "THETA [-81.77983352   5.59908672] nan\n",
      "THETA [-83.18585167   5.64296885] nan\n",
      "THETA [-84.59290464   5.61544956] nan\n",
      "THETA [-85.99823654   5.70566236] nan\n",
      "THETA [-87.40513678   5.68719756] nan\n",
      "THETA [-88.81146004   5.70805803] nan\n",
      "THETA [-90.21816769   5.70194043] nan\n",
      "THETA [-91.62440761   5.72734715] nan\n",
      "THETA [-93.03058125   5.75684413] nan\n",
      "THETA [-94.43629258   5.81785757] nan\n",
      "THETA [-95.84338122   5.78367977] nan\n",
      "THETA [-97.24894677   5.85404566] nan\n",
      "THETA [-98.6558877    5.82937748] nan\n",
      "THETA [-100.06166018    5.88483986] nan\n",
      "THETA [-101.46852282    5.86498577] nan\n",
      "THETA [-102.87404668    5.9370329 ] nan\n",
      "THETA [-104.28100208    5.91019759] nan\n",
      "THETA [-105.68671304    5.96887786] nan\n",
      "THETA [-107.09357914    5.94777687] nan\n",
      "THETA [-108.49915687    6.0152309 ] nan\n",
      "THETA [-109.90607712    5.98997966] nan\n",
      "THETA [-111.3117        6.05396979] nan\n",
      "THETA [-112.71858749    6.03063733] nan\n",
      "THETA [-114.12420715    6.09454531] nan\n",
      "THETA [-115.53108525    6.07156597] nan\n",
      "THETA [-116.93670798    6.13500417] nan\n",
      "THETA [-118.34357604    6.11246801] nan\n",
      "THETA [-119.74920147    6.1755009 ] nan\n",
      "THETA [-121.15606085    6.15335196] nan\n",
      "THETA [-122.56168873    6.21603131] nan\n",
      "THETA [-123.96854063    6.19421958] nan\n",
      "THETA [-125.37417069    6.25659214] nan\n",
      "THETA [-126.78101616    6.23507263] nan\n",
      "THETA [-128.18664815    6.29718009] nan\n",
      "THETA [-129.5934881     6.27591279] nan\n",
      "THETA [-130.99912175    6.33779193] nan\n",
      "THETA [-132.40595695    6.31674158] nan\n",
      "THETA [-133.81159193    6.37842422] nan\n",
      "THETA [-135.21842274    6.35756021] nan\n",
      "THETA [-136.6240581     6.41907088] nan\n",
      "THETA [-138.03088306    6.39836835] nan\n",
      "THETA [-139.4365136     6.45970745] nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/mlenv/lib/python3.5/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n",
      "/home/daniel/mlenv/lib/python3.5/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in multiply\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# some vectorization for better performance\n",
    "def h_vec(theta, X):\n",
    "    return 1 / (1 + np.exp(-np.matmul(X, theta)))\n",
    "\n",
    "def gd_better(theta,  X_train, y_train, alpha):\n",
    "    diff_arr = h_vec(theta, X_train) - y_train\n",
    "    for j in range(len(theta)):\n",
    "        theta[j] = theta[j] - alpha * np.dot(diff_arr, X_train[:, j])\n",
    "        \n",
    "def train_better(X_train, y_train, max_iter, alpha, add_intercept=True):\n",
    "    X_train, y_train = pretrain(X_train, y_train, add_intercept)\n",
    "    theta = np.zeros(X_train.shape[1])\n",
    "    for i in range(max_iter):\n",
    "        gd_better(theta, X_train, y_train, alpha) \n",
    "        if i % 100 == 0:\n",
    "            print('THETA', theta, likelihood(theta, X_train, y_train))\n",
    "    return theta\n",
    "\n",
    "theta = train_better(X_train, y_train, 10000, .003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.3913889] [[ 0.05025845]]\n",
      "[-140.92776034    2.06773864]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(fit_intercept=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.intercept_, clf.coef_)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#fully vectorized - got from http://cs229.stanford.edu/section/vec_demo/lr.ipynb\n",
    "def gd (theta, X_train, y_train, alpha):\n",
    "    theta -= alpha * np.squeeze(np.matmul(np.reshape(h_vec(theta, X_train) - y_train, [1, -1]), X_train))\n",
    "    \n",
    "def train_vec(X_train, y_train, max_iter, alpha, add_intercept=True):\n",
    "    X_train, y_train = pretrain(X_train, y_train, add_intercept)\n",
    "    theta = np.zeros(X_train.shape[1])\n",
    "    for i in range(max_iter):\n",
    "        gd(theta, X_train, y_train, alpha)       \n",
    "    return theta\n",
    "train_vec(X_train, y_train, 1000, .001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
