{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Likelihood-definition:-the-theoretical-probability-(not-technically-a-probability-b/c-does-not-fall-in-[0,1]-of-having-gotten-the-observed-outcomes.\" data-toc-modified-id=\"Likelihood-definition:-the-theoretical-probability-(not-technically-a-probability-b/c-does-not-fall-in-[0,1]-of-having-gotten-the-observed-outcomes.-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Likelihood definition: the theoretical probability (not technically a probability b/c does not fall in [0,1] of having gotten the observed outcomes.</a></span></li><li><span><a href=\"#Objective:-$\\hat{\\theta}_{MLE}-=-\\underset{\\theta}{\\mathrm{argmin}}&#10;\\-L(\\theta;-x_1,x_2,....,x_n)$\" data-toc-modified-id=\"Objective:-$\\hat{\\theta}_{MLE}-=-\\underset{\\theta}{\\mathrm{argmin}}\n",
    "\\-L(\\theta;-x_1,x_2,....,x_n)$-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Objective: $\\hat{\\theta}_{MLE} = \\underset{\\theta}{\\mathrm{argmin}}\n",
    "\\ L(\\theta; x_1,x_2,....,x_n)$</a></span></li><li><span><a href=\"#(conditional)-Likelihood-function-to-maximize\" data-toc-modified-id=\"(conditional)-Likelihood-function-to-maximize-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>(conditional) Likelihood function to maximize</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Note-that-the-$\\theta_0$-value-is-assumed-to-be-included-in-the-vector-and-$x_0-=-1$\" data-toc-modified-id=\"Note-that-the-$\\theta_0$-value-is-assumed-to-be-included-in-the-vector-and-$x_0-=-1$-3.0.0.1\"><span class=\"toc-item-num\">3.0.0.1&nbsp;&nbsp;</span>Note that the $\\theta_0$ value is assumed to be included in the vector and $x_0 = 1$</a></span></li><li><span><a href=\"#Note-also-that-the-&quot;where&quot;-line-is-an-assumption;-we-are-assuming-that-the-probability-that-Y-=-1-is-a-nonlinear-function-(sigmoid-function)-of-a-linear-function-of-x.\" data-toc-modified-id=\"Note-also-that-the-&quot;where&quot;-line-is-an-assumption;-we-are-assuming-that-the-probability-that-Y-=-1-is-a-nonlinear-function-(sigmoid-function)-of-a-linear-function-of-x.-3.0.0.2\"><span class=\"toc-item-num\">3.0.0.2&nbsp;&nbsp;</span>Note also that the \"where\" line is an assumption; we are assuming that the probability that Y = 1 is a nonlinear function (sigmoid function) of a linear function of x.</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Link-function:\" data-toc-modified-id=\"Link-function:-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Link function:</a></span></li><li><span><a href=\"#Log-(conditional)-likelihood-function-to-maximize\" data-toc-modified-id=\"Log-(conditional)-likelihood-function-to-maximize-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Log (conditional) likelihood function to maximize</a></span><ul class=\"toc-item\"><li><span><a href=\"#IMPORTANT-NOTE:-$p_i(x,-\\theta)-=-0$-or-$p_i(x,-\\theta)-=-1$-will-result-in-&quot;RuntimeWarning:-divide-by-zero-encountered-in-log&quot;-i.e.-log(0)-and-log(1-1)-respectively-so-watch-out\" data-toc-modified-id=\"IMPORTANT-NOTE:-$p_i(x,-\\theta)-=-0$-or-$p_i(x,-\\theta)-=-1$-will-result-in-&quot;RuntimeWarning:-divide-by-zero-encountered-in-log&quot;-i.e.-log(0)-and-log(1-1)-respectively-so-watch-out-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>IMPORTANT NOTE: $p_i(x, \\theta) = 0$ or $p_i(x, \\theta) = 1$ will result in \"RuntimeWarning: divide by zero encountered in log\" i.e. log(0) and log(1-1) respectively so watch out</a></span></li></ul></li><li><span><a href=\"#Update-rule-for-maximization-of-likelihood:\" data-toc-modified-id=\"Update-rule-for-maximization-of-likelihood:-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Update rule for maximization of likelihood:</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a14e98160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "\n",
    "data = pd.read_csv('coronary_heart_disease.csv')\n",
    "\n",
    "def s(x):\n",
    "    return 1 / (1 + np.exp(- x))\n",
    "\n",
    "domain = [-6,-5,-4,-3,-2,-1,0,1,2,3,4,5,6]\n",
    "plt.plot(domain, [s(a) for a in domain])\n",
    "plt.title('Sigmoid function on domain [-6,6]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>CHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  CHD\n",
       "0   20    0\n",
       "1   23    0\n",
       "2   24    0\n",
       "3   25    1\n",
       "4   25    0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('coronary_heart_disease.csv')\n",
    "X = data['Age']\n",
    "y = data['CHD']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood definition: the theoretical probability (not technically a probability b/c does not fall in [0,1] of having gotten the observed outcomes.\n",
    "\n",
    "So in maximizing likelihood over all choices of theta, you can imagine that we are trying to recreate in our model the probability distribution (which would be Bernoulli in this case) from which the data is realized (because I believe that this would actually maximize the probability of having gotten the data we observed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective: $\\hat{\\theta}_{MLE} = \\underset{\\theta}{\\mathrm{argmin}}\n",
    "\\ L(\\theta; x_1,x_2,....,x_n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (conditional) Likelihood function to maximize\n",
    "$$ L(\\theta; x_1, x_2,...,x_n) = \\prod_{i=1}^{N} p_{i}^{y_i}(1 - p_i)^{1 - y_i},$$\n",
    "<br>\n",
    "where $p_i = p(Y = 1 \\mid x_i; \\theta) = \\sigma(\\sum_{j=1}^{M} \\theta_jx_{ij}) = \\dfrac{1}{1 + \\mathrm{e}^{-(\\sum_{j=1}^{M} \\theta_jx_{ij})}}$\n",
    "###### Note that the $\\theta_0$ value is assumed to be included in the vector and $x_0 = 1$\n",
    "###### Note also that the \"where\" line is an assumption; we are assuming that the probability that Y = 1 is a nonlinear function (sigmoid function) of a linear function of x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link function: \n",
    "This function, $g$, takes the mean response and returns back the linear combination of predictors and theta. $g$ is the inverse of the sigmoid function. Therefore, $g^{-1}(z)$ will be your prediction (i.e. $p(Y = 1 \\mid X; \\theta)$), where $z$ is the linear combination of theta and your predictors. This is how logistic regression fits into generalized linear models. Note that for generalized linear models use only exponential family distributions to model the response variable. \n",
    "\n",
    "The below equation gives the log odds for a single training example (x value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\log\\dfrac{p}{1-p} = \\sum_{j=1}^{M} \\theta_jx_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log (conditional) likelihood function to maximize\n",
    "\n",
    "This can be done because log is a monotonic function (always increasing => x1 > x2 => log(x1) > log(x2)). This means that the same theta that maximizes the log likelihood also maximizes the likelihood. This also makes the likelihood much easier to differentiate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "LCL = \\sum_{i=1}^{N}\\log L(\\theta; y_i \\mid x_i) \n",
    "    = \\sum_{i:y_i=1} \\log p_i + \\sum_{i:y_i=0} \\log (1 - p_i) \n",
    "    = \\sum_{i=1}^{N} y_i\\log p_i + (1-y_i)\\log(1 - p_i) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTANT NOTE: $p_i(x, \\theta) = 0$ or $p_i(x, \\theta) = 1$ will result in \"RuntimeWarning: divide by zero encountered in log\" i.e. log(0) and log(1-1) respectively so watch out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = .000000001\n",
    "def likelihood(theta, X_train, y_train):\n",
    "    s = 0.0\n",
    "    for i in range(len(X_train)):\n",
    "        p = sigmoid_hypothesis(theta, X_train[i, :])\n",
    "        if y_train[i] == 1:\n",
    "            s += np.log(p+eps)\n",
    "        else:\n",
    "            if (1 - p) == 0:\n",
    "                s += np.log(1-p+eps)\n",
    "            else:\n",
    "                s += np.log(1-p)\n",
    "        # s += y_train[i]*np.log(p) + (1-y_train[i])*np.log(1-p)\n",
    "    return s\n",
    "\n",
    "def sigmoid_hypothesis(theta, x):\n",
    "    return 1 / (1 + np.exp(-np.dot(theta, x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update rule for maximization of likelihood:\n",
    "$$ \\beta_j = \\beta_j + \\alpha \\sum_{i=1}^{N} (y_i - p_i)x_{ij}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.83754541e+00,  1.83776165e-03])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ga_element_wise(theta, X_train, y_train, alpha):\n",
    "    diff_y_p = np.zeros([len(y_train)])\n",
    "    for m in range(len(y_train)):\n",
    "            diff_y_p[m] = \\\n",
    "            sigmoid_hypothesis(theta, \n",
    "                               X_train[m, :]) - y_train[m]\n",
    "    for j in range(len(theta)):\n",
    "        # This is the sum next to alpha \n",
    "        s = 0.0\n",
    "        for m in range(len(y_train)):\n",
    "            s += diff_y_p[m] * X_train[m, j]\n",
    "        theta[j] = theta[j] - alpha * s\n",
    "\n",
    "def pretrain(X_train, y_train, add_intercept=True):\n",
    "    if y_train.ndim != 1: \n",
    "        raise Exception('y_train should be 1D')\n",
    "    y_train = np.array(y_train)\n",
    "    if X_train.ndim == 1: \n",
    "        # Makes X_train an array of arrays each w/ 1 element\n",
    "        X_train = X_train.values.reshape(-1, 1)\n",
    "    # Add intercept for x_0 = 1 \n",
    "    if add_intercept:\n",
    "        # insert goes arr, index, value, dimension to insert\n",
    "        # it will insert for each array in the given dimension\n",
    "        # i.e. it is broadcasted \n",
    "        X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "        \n",
    "    return [X_train, y_train]\n",
    "        \n",
    "def train_element_wise(X_train, y_train, max_iter, alpha, \n",
    "                      add_intercept=True):\n",
    "    X_train, y_train = pretrain(X_train, y_train, add_intercept)\n",
    "        \n",
    "    # length of theta should be === # features \n",
    "    theta = np.zeros(X_train.shape[1])\n",
    "    for i in range(max_iter):\n",
    "        ga_element_wise(theta, X_train, y_train, alpha)       \n",
    "    return theta\n",
    "\n",
    "train_element_wise(X_train, y_train, 1000, .001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some vectorization for better performance\n",
    "def h_vec(theta, X):\n",
    "    return 1 / (1 + np.exp(-np.matmul(X, theta)))\n",
    "\n",
    "def gd_better(theta,  X_train, y_train, alpha):\n",
    "    diff_arr = h_vec(theta, X_train) - y_train\n",
    "    for j in range(len(theta)):\n",
    "        theta[j] = theta[j] - alpha * np.dot(diff_arr, X_train[:, j])\n",
    "        \n",
    "def train_better(X_train, y_train, max_iter, alpha, add_intercept=True):\n",
    "    X_train, y_train = pretrain(X_train, y_train, add_intercept)\n",
    "    theta = np.zeros(X_train.shape[1])\n",
    "    for i in range(max_iter):\n",
    "        gd_better(theta, X_train, y_train, alpha) \n",
    "        if i % 100 == 0:\n",
    "            print('THETA', theta, likelihood(theta, X_train, y_train))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.3913889] [[0.05025845]]\n",
      "-307.9281626342554\n",
      "-37.958385673769065\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(fit_intercept=True)\n",
    "clf.fit(X_train.values.reshape(-1, 1), y_train)\n",
    "\n",
    "print(clf.intercept_, clf.coef_)\n",
    "#print(theta)\n",
    "print(likelihood(theta, \n",
    "                 np.insert(X_train.values.reshape(-1, 1), 0, 1, axis=1), \n",
    "                 np.array(y_train)))\n",
    "\n",
    "print(likelihood(np.array([-2.3913889, 0.05025845]), \n",
    "                 np.insert(X_train.values.reshape(-1, 1), 0, 1, axis=1), \n",
    "                 np.array(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-263.23337509    4.54631318] -307.92816741514736\n"
     ]
    }
   ],
   "source": [
    "#fully vectorized - got from http://cs229.stanford.edu/section/vec_demo/lr.ipynb\n",
    "def gd (theta, X_train, y_train, alpha):\n",
    "    theta -= alpha * np.squeeze(np.matmul(np.reshape(h_vec(theta, X_train) - y_train, [1, -1]), X_train))\n",
    "    \n",
    "def train_vec(X_train, y_train, max_iter, alpha, add_intercept=True):\n",
    "    X_train, y_train = pretrain(X_train, y_train, add_intercept)\n",
    "    theta = np.zeros(X_train.shape[1])\n",
    "    for i in range(max_iter):\n",
    "        gd(theta, X_train, y_train, alpha)  \n",
    "        #print(likelihood(theta, X_train, y_train))\n",
    "    return theta\n",
    "theta = train_vec(X_train, y_train, 100000, .003)\n",
    "print(theta, likelihood(np.array([-42.49060329, 0.60499953]), \n",
    "                 np.insert(X_train.values.reshape(-1, 1), 0, 1, axis=1), \n",
    "                 np.array(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
